import os
import shutil
import matplotlib.pyplot as plt
import psutil
import torch
from torch.utils.tensorboard import SummaryWriter
from datetime import datetime
import numpy as np

from PIL import ImageFont

from model.char.config import CheckpointConfig, BaseConfig


def clear_dir(path):
    # æ¸…ç©ºç›®å½•å‰éªŒè¯
    if os.path.exists(path):
        print(f"â™»ï¸ æ¸…ç©ºå·²æœ‰æ•°æ®ï¼š{path} (å…±{len(os.listdir(path))}ä¸ªæ—§æ ·æœ¬)")
        shutil.rmtree(path)  # åˆ é™¤æ•´ä¸ªç›®å½•æ ‘
        os.mkdir(path)  # é‡æ–°åˆ›å»ºç›®å½•
    else:
        print(f"ğŸ“ ç›®å½•ä¸å­˜åœ¨ï¼Œå·²é‡æ–°åˆ›å»º: {path}")
        os.mkdir(path)  # é‡æ–°åˆ›å»ºç›®å½•


def load_fonts(font_dir):
    """åŠ è½½å¹¶éªŒè¯å­—ä½“æ–‡ä»¶"""
    valid_fonts = []
    for filename in os.listdir(font_dir):
        font_path = os.path.join(font_dir, filename)
        try:
            # éªŒè¯å­—ä½“æœ‰æ•ˆæ€§
            font = ImageFont.truetype(font_path, size=20)
            valid_fonts.append(font_path)
        except Exception as e:
            print(f"âš ï¸ è·³è¿‡æ— æ•ˆå­—ä½“: {filename} ({str(e)})")
    return valid_fonts


def create_experiment_dir(model_name, model_params):
    """åˆ›å»ºå®éªŒç›®å½•"""
    params = {
        'timestamp': datetime.now().strftime("%Y-%m-%d_%H-%M"),
        'model_name': model_name,
        'batch_size': model_params['batch_size'],
        'lr': model_params['lr'],
    }
    dir_name = CheckpointConfig.EXPERIMENT_FORMAT.format(**params)
    exp_dir = os.path.join(CheckpointConfig.CHECKPOINT_ROOT, dir_name)
    os.makedirs(exp_dir, exist_ok=True)
    return exp_dir


def save_checkpoint(model, epoch):
    """æ£€æŸ¥ç‚¹ä¿å­˜"""
    if epoch % model.save_interval == 0 or epoch == model.epochs:
        # å¼‚æ­¥ä¿å­˜
        import threading
        save_thread = threading.Thread(
            target=_save_checkpoint,
            args=(model, epoch,)
        )
        save_thread.start()


def _save_checkpoint(model, epoch):
    checkpoint_path = os.path.join(
        model.experiment_dir,
        f'{model.name}_epoch{epoch}.pth'
    )
    # ä¿å­˜å®Œæ•´è®­ç»ƒçŠ¶æ€
    torch.save({
        'model_class' : model.__class__.__name__,
        'model_module': model.__class__.__module__,
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': model.optimizer.state_dict(),
        'scheduler_state_dict': model.scheduler.state_dict(),
    }, checkpoint_path)

    cleanup_old_checkpoints(model)


def cleanup_old_checkpoints(model):
    """ä¿®æ­£åçš„æ£€æŸ¥ç‚¹æ¸…ç†é€»è¾‘"""
    # è·å–æ‰€æœ‰æ¨¡å‹æ£€æŸ¥ç‚¹æ–‡ä»¶
    checkpoints = [
        f for f in os.listdir(model.experiment_dir)
        if f.endswith('.pth')
    ]

    # æŒ‰epochæ’åºï¼ˆæå–æ–‡ä»¶åä¸­çš„epochæ•°å­—ï¼‰
    checkpoints.sort(key=lambda x: int(x.split('_epoch')[1].split('.')[0]))

    # ä¿ç•™æœ€æ–°çš„max_checkpointsä¸ª
    while len(checkpoints) > model.max_checkpoints:
        old_checkpoint = checkpoints.pop(0)
        os.remove(os.path.join(model.experiment_dir, old_checkpoint))
        print(f"ğŸ§¹ å·²æ¸…ç†æ—§æ£€æŸ¥ç‚¹: {old_checkpoint}")


def cleanup_intermediate_checkpoints(experiment_dir):
    """æ¸…ç†ä¸­é—´æ£€æŸ¥ç‚¹"""
    for f in os.listdir(experiment_dir):
        if f.endswith('.pth') and 'epoch' in f:
            os.remove(os.path.join(experiment_dir, f))
            print(f"ğŸ§¹ æ¸…ç†ä¸­é—´æ£€æŸ¥ç‚¹: {f}")


def save_final_model(model):
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = os.path.join(model.experiment_dir, f'{model.name}.pth')
    torch.save({
        'model_class' : model.__class__.__name__,
        'model_module': model.__class__.__module__,
        'model_state_dict': model.state_dict(),
    }, final_model_path)

    # ä¿å­˜é…ç½®æ–‡ä»¶
    save_training_config(model)

    # æ¸…ç†ä¸­é—´æ£€æŸ¥ç‚¹
    cleanup_intermediate_checkpoints(model.experiment_dir)


def save_training_config(model):
    """ç‹¬ç«‹ä¿å­˜é…ç½®çš„æ–¹æ³•"""
    config_path = os.path.join(model.experiment_dir, 'training_config.json')
    config = {
        'model': {
            'name': model.name,
            'class': model.__class__.__name__,
            'conv_dropout': model.conv_dropout,
            'shared_dropout': model.shared_dropout,
            'head_dropout': model.head_dropout,
            'captcha_length': model.captcha_length,
            'num_classes': model.num_classes,
            'se_ratio': getattr(model, 'se_ratio', 0.25),
            'attention_layers': getattr(model, 'attention_layers', []),
        },
        'training': {
            'batch_size': model.batch_size,
            'epochs': model.epochs,
            'lr': model.lr,
            'weight_decay': model.weight_decay,
            'early_stop_patience': model.early_stop_patience,
            'early_stop_delta': model.early_stop_delta,
            'final_metrics': {
                'best_val_loss': model.best_val_loss,
                'best_val_acc': max(model.val_accs) if model.val_accs else 0,
                'total_epochs': len(model.train_losses)
            }
        },
        'dataset': {
            'IMAGE_SIZE': BaseConfig.IMAGE_SIZE,
            'CHAR_SET': BaseConfig.CHAR_SET,
            'CAPTCHA_LENGTH': BaseConfig.CAPTCHA_LENGTH,
            'NUM_CLASSES': BaseConfig.NUM_CLASSES
        },
        'environment': {
            'saved_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'device': str(model.device),
            'torch_version': torch.__version__
        }
    }

    import json
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“„ é…ç½®æ–‡ä»¶å·²ä¿å­˜è‡³: {config_path}")


def log_startup_info(model):
    """ä¼˜åŒ–åçš„è®­ç»ƒå¯åŠ¨ä¿¡æ¯ï¼ˆèšç„¦æ ¸å¿ƒå‚æ•°ï¼‰"""
    # æ ¸å¿ƒä¿¡æ¯åˆ†ç±»
    env_info = {
        "PyTorch Ver": torch.__version__,
        "CUDA Available": "âœ…" if torch.cuda.is_available() else "âŒ",
        "GPU Name": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "N/A",
    }

    hardware_info = {
        "CPU Cores": os.cpu_count(),
        "RAM": f"{psutil.virtual_memory().total / 1024 ** 3:.1f}G",
    }

    training_config = {
        "Batch Size": model.batch_size,
        "Init LR": model.lr,
        "Weight Decay": model.weight_decay,
        "Max Epochs": model.epochs,
        "Early Stop": f"{model.early_stop_patience} epochs (Î”<{model.early_stop_delta})",
        "Tracking Positions": model.captcha_length
    }

    dataset_info = {
        "Image Size": BaseConfig.IMAGE_SIZE,
        "Char Length": BaseConfig.CAPTCHA_LENGTH,
        "Char Classes": BaseConfig.NUM_CLASSES,
        "Train Samples": len(model.train_dataset),
        "Valid Samples": len(model.val_dataset)
    }

    model_info = {
        "Backbone": "ResNet",
        "Attention": "SE Block",
        "Total Params": f"{sum(p.numel() for p in model.parameters()) / 1e6:.2f}M"
    }

    # ä¿¡æ¯æ’ç‰ˆ
    def format_section(title, items, width=40):
        lines = [f"â•â• {title} â•" + "â•" * (width - len(title) - 4)]
        for k, v in items.items():
            line = f"â”‚ {k:<16} {v}"
            lines.append(line.ljust(width - 1) + "â”‚")
        return "\n".join(lines)

    # æ„å»ºæ˜¾ç¤ºå†…å®¹
    content = [
        format_section("Environment", env_info),
        format_section("Hardware", hardware_info),
        format_section("Training Config", training_config),
        format_section("Dataset Info", dataset_info),
        format_section("Model Architecture", model_info),
        f"â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯",
        f"ğŸ“ Experiment Dir: {model.experiment_dir}"
    ]

    # æ‰“å°ä¿¡æ¯
    print("\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Training Session â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®")
    print("\n".join(content))
